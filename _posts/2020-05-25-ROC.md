---
layout: post
title: "Backpropagation"
---

The ROC curve

A ROC curve plots true positives vs. false positives. Consider the following example. You have n<sub>H</sub> hares and n<sub>T</sub> tortoises. You have a classifier to identify hares (for simplicity, think for instance of a simple classifier based on a sharp running speed threshold). The maximum amount of true positives is n<sub>H</sub>. The maximum amount of false positives is n<sub>T</sub>. There are n<sub>H</sub> * n<sub>T</sub> pairwise comparisons.
For instance if you rank the speed of hares vs tortoises, and the result is HHHTHTHTH, then the ROC curve (black) looks like this:

The first tortoise (i.e. false positive hare) is beaten by three hares, the second by four and the third and fourth by five hares. The area under the ROC curve is the normalized number of wins of hares U.
	AUC = U/nH*nT

The Mann-Whitney U Test
The Mann-Whitney U Test uses the number of wins (e.g. of hares) as test statistic U, which is compared against significance tables

The GINI coefficient
The GINI coefficient is half the area between the ROC curve and the identity line.
